
Welcome to the Plexe API documentation. Plexe is an automated machine learning model generation platform that allows you to create custom ML models from your data with simple API calls.

## Authentication

All API endpoints require authentication using an API key. Include your API key in the `x-api-key` header with all requests:

```bash
x-api-key: your_api_key_here
```

## Base URL

```
https://api.plexe.ai/v0
```

## Workflow

1. Upload your training data files
2. Create a model using the uploaded data
3. Check model training status
4. Use the model for inference once training is complete

## Endpoints

#### Data Management

##### Upload Training Data
```http
POST /v0/uploads
```

Upload your training data files. Supports multiple files and ZIP archives.

**Request:**
- Content-Type: `multipart/form-data`
- Body: Form data containing one or more files

```bash
curl -X POST https://api.plexe.ai/v0/uploads \
  -H "x-api-key: your_api_key_here" \
  -F "files=@your_data.csv" \
  -F "files=@additional_data.zip"
```

**Response:**
```json
{
  "upload_id": "550e8400-e29b-41d4-a716-446655440000"
}
```

#### Delete Upload
```http
DELETE /v0/uploads/{upload_id}
```

Remove previously uploaded training data. Call this after model creation or if you want to cancel the upload.

**Path Parameters:**
- `upload_id` (required): The ID received from the upload endpoint

### Model Management

#### Create a Model
```http
POST /v0/models/{model_name}/create
```

Start training a new model using your uploaded data.

**Path Parameters:**
- `model_name` (required): Name for your model

**Request Body:**
```json
{
  "upload_id": "550e8400-e29b-41d4-a716-446655440000",
  "goal": "Predict customer churn based on usage patterns",
  "eval": "accuracy"  // Optional
}
```

**Response:**
```json
{
  "model_version": "model_20231118_001"
}
```

#### Check Model Status
```http
GET /v0/models/{model_name}/{model_version}/status
```

Check the training status of your model.

**Path Parameters:**
- `model_name` (required): Name of the model
- `model_version` (required): Version ID returned from model creation

**Response:**
```json
{
  "status": "completed",  // possible values: "pending", "running", "completed", "failed"
  "result": {
    "code": "def predict(data): ...",  // Only present when status is "completed"
    "valid_metric": 0.87  // Only present when status is "completed"
  },
  "error": null  // Only present when status is "failed"
}
```

#### Perform Inference
```http
POST /v0/models/{model_name}/{model_version}/infer
```

Use a trained model to make predictions.

**Path Parameters:**
- `model_name` (required): Name of the model
- `model_version` (required): Version of the model

## Error Handling

The API uses standard HTTP response codes:

- 200: Success
- 400: Bad Request (invalid parameters)
- 401: Unauthorized (invalid API key)
- 404: Not Found (invalid model_name or model_version)
- 500: Internal Server Error

Error responses include a detail message:
```json
{
  "detail": "Error description"
}
```

## Rate Limiting

- Upload size limit: Contact support for current limits
- Maximum concurrent model training: Contact support for current limits
- API calls per minute: Contact support for current limits

For higher limits or special requirements, please contact our support team.

